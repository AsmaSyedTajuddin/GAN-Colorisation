{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "gan_colorization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sC2k_l6A9eJS",
        "outputId": "f172e85d-656e-4cad-b97d-08c29d9adf62"
      },
      "source": [
        "# !pip uninstall fastai -y\r\n",
        "# !pip install fastai\r\n",
        "\r\n",
        "import fastai\r\n",
        "fastai.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S_KF6DM0tF9",
        "outputId": "bf1c3d63-af55-411c-aec4-5d40d79168ce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "EyZEyKsNx3DB"
      },
      "source": [
        "# @title Download dataset\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import time\r\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\r\n",
        "\r\n",
        "if not os.path.exists(\"/content/images/valid.zip\"):\r\n",
        "    # https://drive.google.com/file/d/1bXD5hR5WlIB6LsqDHmNn29EMA43Z82f3/view?usp=sharing\r\n",
        "    gdd.download_file_from_google_drive(file_id='1bXD5hR5WlIB6LsqDHmNn29EMA43Z82f3',\r\n",
        "                                        dest_path='./images/valid.zip',\r\n",
        "                                        unzip=True,\r\n",
        "                                        showsize=True,\r\n",
        "                                        )\r\n",
        "    # !rm -rf /content/images/valid.zip\r\n",
        "\r\n",
        "# download scripts\r\n",
        "!rm -rf *.py\r\n",
        "time.sleep(2)\r\n",
        "\r\n",
        "!wget -q https://raw.githubusercontent.com/veb-101/GAN-Colorisation/master/trainer.py -O trainer.py\r\n",
        "!wget -q https://raw.githubusercontent.com/veb-101/GAN-Colorisation/master/utils.py -O utils.py\r\n",
        "!wget -q https://raw.githubusercontent.com/veb-101/GAN-Colorisation/master/model.py -O model.py\r\n",
        "!wget -q https://raw.githubusercontent.com/veb-101/GAN-Colorisation/master/data_loader.py -O data_loader.py\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "if not os.path.exists(\"/content/images/train.zip\"):\r\n",
        "    # https://drive.google.com/file/d/1c5WQwglbVL9S_LHH5E9XU9bCWLzZg_V7/view?usp=sharing\r\n",
        "    gdd.download_file_from_google_drive(file_id='1c5WQwglbVL9S_LHH5E9XU9bCWLzZg_V7',\r\n",
        "                                        dest_path='./images/train.zip',\r\n",
        "                                        unzip=True,\r\n",
        "                                        showsize=True,\r\n",
        "                                        )\r\n",
        "    # !rm -rf /content/images/train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-27T18:42:27.570244Z",
          "start_time": "2021-01-27T18:42:21.959937Z"
        },
        "id": "XG_w56WAx1a4",
        "cellView": "form"
      },
      "source": [
        "#@title setup\n",
        "import os\n",
        "import gc\n",
        "import random\n",
        "import warnings\n",
        "import importlib\n",
        "import numpy as np\n",
        "# from tqdm. import tqdm\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "import model\n",
        "import utils\n",
        "import trainer\n",
        "import data_loader\n",
        "\n",
        "seed = 41\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "importlib.reload(data_loader)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(trainer)\n",
        "importlib.reload(model)\n",
        "\n",
        "from trainer import MainModel\n",
        "from utils import init_model\n",
        "from data_loader import make_dataloaders\n",
        "from utils import update_losses, visualize\n",
        "from utils import init_model, AverageMeter\n",
        "from utils import create_loss_meters, log_results\n",
        "from model import Generator_Res_Unet, Discriminator\n",
        "\n",
        "\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "device = get_default_device()\n",
        "\n",
        "warnings.simplefilter(\"ignore\", UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJJ9Im3p6_iC"
      },
      "source": [
        "def train_model(model, train_dl, valid_dl, start_epoch, epochs):\r\n",
        "    # getting a batch for visualizing the model output after fixed intrvals\r\n",
        "    savedir = \"/content/gan_train\"\r\n",
        "    os.makedirs(savedir, exist_ok=True)\r\n",
        "\r\n",
        "    for e in range(start_epoch, start_epoch+epochs):\r\n",
        "        loss_meter_dict = create_loss_meters()\r\n",
        "        training_loader_iter = iter(train_dl)\r\n",
        "        length_train = len(training_loader_iter)\r\n",
        "        \r\n",
        "        for i in tqdm(length_train, desc=f\"Epoch: [{e}/{start_epoch+epochs-1}]\"):\r\n",
        "            data = next(training_loader_iter)\r\n",
        "            model.setup_input(data)\r\n",
        "            model.optimize()\r\n",
        "            \r\n",
        "            # function updating the log objects\r\n",
        "            update_losses(model, loss_meter_dict, count=data[\"L\"].size(0)) \r\n",
        "            \r\n",
        "            if i == 0 or i == int(length_train / 2) or i == (length_train - 1):\r\n",
        "                print(f\"Iteration:[{i}/{length_train}]\")\r\n",
        "                # function to print out the losses\r\n",
        "                log_results(loss_meter_dict)  \r\n",
        "            \r\n",
        "        for idx, valid_data in enumerate(valid_dl):\r\n",
        "            visualize(model, valid_data, save_name=os.path.join(savedir, f\"Validation_Epoch_{e}-{idx}.png\"))\r\n",
        "        \r\n",
        "        torch.save({\r\n",
        "            \"epoch\": e,\r\n",
        "            \"net_G\": model.net_G.state_dict(),\r\n",
        "            \"opt_G\": model.opt_G.state_dict(),\r\n",
        "            \"scaler_G\": model.scaler_G.state_dict(),\r\n",
        "            \"net_D\": model.net_D.state_dict(),\r\n",
        "            \"opt_D\": model.opt_D.state_dict(),\r\n",
        "            \"scaler_D\": model.scaler_D.state_dict(),\r\n",
        "        }, f\"gan_checkpoint_{e}.tar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_SS-jHsx1bA"
      },
      "source": [
        "def load_model(config, ckpt_number=-1, device=None, prefix=\"warm_\"):\n",
        "    \n",
        "    lr_G = config[\"lr_G\"]\n",
        "    lr_D = config[\"lr_D\"]\n",
        "    beta1 = config[\"beta1\"]\n",
        "    beta2 = config[\"beta2\"]\n",
        "    load_previous = config[\"load_previous\"]\n",
        "    \n",
        "    epoch = 0\n",
        "    gen_model = Generator_Res_Unet()\n",
        "    net_G = init_model(gen_model.get_model(), device)\n",
        "\n",
        "    net_D = init_model(Discriminator(input_channels=3), device)\n",
        "    scaler_G = GradScaler()\n",
        "    scaler_D = GradScaler()\n",
        "\n",
        "    opt_G = optim.Adam(net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
        "    opt_D = optim.Adam(net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
        "\n",
        "    drive_path = r\"/content/drive/MyDrive/Project-Colorisation\"\n",
        "    drive_path = r\"/content/\"\n",
        "    print(f\"[*] Finding checkpoint {ckpt_number} in {drive_path}\")\n",
        "\n",
        "    checkpoint_file = f\"{prefix}checkpoint_{ckpt_number}.tar\"\n",
        "    checkpoint_path = os.path.join(drive_path, checkpoint_file)\n",
        "\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        print(f\"[!] No checkpoint for epoch {ckpt_number}\")\n",
        "    else:    \n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "        epoch = checkpoint[\"epoch\"]\n",
        "\n",
        "        net_G.load_state_dict(checkpoint[f\"net_G\"])\n",
        "        print(\"Generator weight loaded\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            net_D.load_state_dict(checkpoint[f\"net_D\"])\n",
        "            print(\"Discriminator weights loaded.\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        if load_previous:\n",
        "            try:  \n",
        "                opt_D.load_state_dict(checkpoint[f\"opt_D\"])\n",
        "                print(\"Discriminator optimizer loaded.\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            opt_G.load_state_dict(checkpoint[f\"opt_G\"])\n",
        "            print(\"Optimizer's state loaded\")\n",
        "            \n",
        "            try:\n",
        "                scaler_G.load_state_dict(checkpoint[f\"scaler_G\"])\n",
        "                print(\"Grad Scaler - Generator loaded\")\n",
        "                scaler_D.load_state_dict(checkpoint[f\"scaler_D\"])\n",
        "                print(\"Grad Scaler - Discriminator loaded\")\n",
        "            except Exception as e:\n",
        "                pass\n",
        "        \n",
        "\n",
        "    return_ = {\n",
        "        \"epoch\": epoch,\n",
        "        \"net_G\": net_G,\n",
        "        \"opt_G\": opt_G,\n",
        "        \"scaler_G\": scaler_G,\n",
        "        \"net_D\": net_D,\n",
        "        \"scaler_D\": scaler_D,\n",
        "        \"opt_D\": opt_D\n",
        "    }\n",
        "    return return_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-28T06:46:41.145932Z",
          "start_time": "2021-01-28T06:46:41.139971Z"
        },
        "id": "ONnUSePzx1bE"
      },
      "source": [
        "def pretrain_generator(train_dl, valid_dl, net, scaler, opt, criterion, start_epoch, epochs):\n",
        "    savedir = \"/content/warmup\"\n",
        "    os.makedirs(savedir, exist_ok=True)\n",
        "    \n",
        "    for e in range(start_epoch, start_epoch+epochs):\n",
        "        loss_meter = AverageMeter()\n",
        "        training_loader_iter = iter(train_dl)\n",
        "        length_train = len(training_loader_iter)\n",
        "        \n",
        "        for i in tqdm(length_train, desc=f\"Epoch: [{e}/{start_epoch+epochs-1}]\"):\n",
        "            data = next(training_loader_iter)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            L, ab = data['L'].to(device), data['ab'].to(device)\n",
        "\n",
        "            with autocast():\n",
        "                preds = net(L)\n",
        "                loss = criterion(preds, ab)\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            # loss.backward()\n",
        "            # opt.step()\n",
        "            loss_meter.update(loss.detach().item(), L.size(0))\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            \n",
        "            if i == 0 or i == int(length_train / 2) or i == (length_train - 1):\n",
        "                print(f\"L1 Loss: [{loss_meter.avg:.5f}]\")\n",
        "        \n",
        "        for idx, valid_data in enumerate(valid_dl):\n",
        "            visualize(net, valid_data, save_name=os.path.join(savedir, f\"Validation_Epoch_{e}-{idx}.png\"))\n",
        "            \n",
        "        torch.save({\n",
        "            \"epoch\": e,\n",
        "            \"net_G\": net.state_dict(),\n",
        "            \"opt_G\": opt.state_dict(),\n",
        "            \"scaler_G\": scaler.state_dict(),\n",
        "        }, f\"warm_checkpoint_{e}.tar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-01-27T18:43:02.033511Z",
          "start_time": "2021-01-27T18:43:02.017421Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sCTOIdhx1bC",
        "outputId": "5911c9f2-4ff8-4d90-e220-c374230e8783"
      },
      "source": [
        "train_ = \"/content/images/train\"\n",
        "valid_ = \"/content/images/valid\"\n",
        "\n",
        "device = get_default_device()\n",
        "\n",
        "train_dl = make_dataloaders(path=train_, num_images=2)\n",
        "valid_dl = make_dataloaders(path=valid_, num_images=2, is_training=False, shuffle=False)\n",
        "    \n",
        "print(f\"Number of batches ::Train:: {len(train_dl)}, ::Valid:: {len(valid_dl)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of batches ::Train:: 1, ::Valid:: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQfQdahOx1bF"
      },
      "source": [
        "config = {\n",
        "    \"lr_G\": 1e-4,\n",
        "    \"lr_D\": 2e-4,\n",
        "    \"beta1\": 0.5,\n",
        "    \"beta2\": 0.999,\n",
        "    \"lambda_L1\": 100.0,\n",
        "    \"load_previous\": True\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OulVfPHbx1bG",
        "cellView": "form"
      },
      "source": [
        "#@title Warmup generator\r\n",
        "\r\n",
        "config[\"load_previous\"] = False # First run\r\n",
        "# config[\"load_previous\"] = True # uncomment for subsequent runs of same Type\r\n",
        "\r\n",
        "load_ckpt = -1\r\n",
        "gen_load = load_model(config, ckpt_number=load_ckpt, device=device, prefix=\"warm_\")\r\n",
        "\r\n",
        "net_G = gen_load[\"net_G\"]\r\n",
        "scaler_G = gen_load[\"scaler_G\"]\r\n",
        "opt_G = gen_load[\"opt_G\"]\r\n",
        "last_epoch = gen_load[\"epoch\"]\r\n",
        "\r\n",
        "criterion = nn.L1Loss()     \r\n",
        "criterion.to(device)\r\n",
        "start_epoch = last_epoch + 1\r\n",
        "epochs = 30\r\n",
        "\r\n",
        "pretrain_generator(train_dl, valid_dl, net_G, scaler_G, opt_G, criterion, start_epoch, epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5EKjQjtx1bH"
      },
      "source": [
        "# train Gan model\n",
        "\n",
        "config[\"lr_G\"] = 2e-4\n",
        "\n",
        "config[\"load_previous\"] = False # First run\n",
        "# config[\"load_previous\"] = True # uncomment for subsequent runs of same Type\n",
        "\n",
        "load_ckpt = -1\n",
        "gan_load = load_model(config, ckpt_number=load_ckpt, device=device, prefix=\"warm_\")\n",
        "\n",
        "# pretrained Generator \n",
        "net_G = gan_load[\"net_G\"]\n",
        "scaler_G = gan_load[\"scaler_G\"]\n",
        "opt_G = gan_load[\"opt_G\"]\n",
        "\n",
        "# newly Discriminator if load_previous = False else previously trained\n",
        "net_D = gan_load[\"net_D\"]\n",
        "scaler_D = gan_load[\"scaler_D\"]\n",
        "opt_D = gan_load[\"opt_D\"]\n",
        "\n",
        "last_epoch = gan_load[\"epoch\"] \n",
        "\n",
        "last_epoch = 0\n",
        "start_epoch = last_epoch + 1\n",
        "epochs = 100\n",
        "\n",
        "model = MainModel(net_G=net_G,\n",
        "                  net_D=net_D,\n",
        "                  scaler_G=scaler_G,\n",
        "                  scaler_D=scaler_D,\n",
        "                  opt_G=opt_G,\n",
        "                  opt_D=opt_D,\n",
        "                  device=device)\n",
        "\n",
        "train_model(config, train_dl, valid_dl, start_epoch, epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7bsyig52tYz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}